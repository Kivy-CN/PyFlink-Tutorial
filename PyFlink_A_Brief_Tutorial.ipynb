{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyFlink Installation\n",
    "\n",
    "### By Fatty Yu\n",
    "\n",
    "### Version 2023.11.15\n",
    "\n",
    "## Anaconda3 Installation\n",
    "\n",
    "Download the Anaconda3 package from TUNA first.\n",
    "\n",
    "```Bash\n",
    "wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.09-0-Linux-x86_64.sh\n",
    "sh Anaconda3-2023.09-0-Linux-x86_64.sh\n",
    "```\n",
    "During the installation, please use the default settings.\n",
    "It should be installed at `~/anaconda3`.\n",
    "\n",
    "## Python 3.9 Installation\n",
    "\n",
    "Python 3.9 installed by conda will be easy and reliable.\n",
    "\n",
    "```Bash\n",
    "conda create -n pyflink_39 python=3.9\n",
    "conda activate pyflink_39\n",
    "```\n",
    "\n",
    "## Apache-Flink Installation\n",
    "\n",
    "Then install the apache-flink package with pip.\n",
    "\n",
    "```Bash\n",
    "pip install apache-flink\n",
    "```\n",
    "\n",
    "## Some Tests\n",
    "\n",
    "The following code comes from the official [documents version 1.18](https://nightlies.apache.org/flink/flink-docs-release-1.18/docs/dev/python/datastream_tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n",
      "Using Any for unsupported type: typing.Sequence[~T]\n",
      "No module named google.cloud.bigquery_storage_v1. As a result, the ReadFromBigQuery transform *CANNOT* be used with `method=DIRECT_READ`.\n",
      "Executing word_count example with default input data set.\n",
      "Use --input to specify file input.\n",
      "Printing result to stdout. Use --output to specify output path.\n"
     ]
    }
   ],
   "source": [
    "# Test with a Flink Python DataStream API Program\n",
    "# The following code comes from the official [documents version 1.18](https://nightlies.apache.org/flink/flink-docs-release-1.18/docs/dev/python/datastream_tutorial/).\n",
    "# Save the code below as `DataStream_API_word_count.py`.\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from pyflink.common import WatermarkStrategy, Encoder, Types\n",
    "from pyflink.datastream import StreamExecutionEnvironment, RuntimeExecutionMode\n",
    "from pyflink.datastream.connectors.file_system import FileSource, StreamFormat, FileSink, OutputFileConfig, RollingPolicy\n",
    "\n",
    "\n",
    "word_count_data = [\"To be, or not to be,--that is the question:--\",\n",
    "                   \"Whether 'tis nobler in the mind to suffer\",\n",
    "                   \"The slings and arrows of outrageous fortune\",\n",
    "                   \"Or to take arms against a sea of troubles,\",\n",
    "                   \"And by opposing end them?--To die,--to sleep,--\",\n",
    "                   \"No more; and by a sleep to say we end\",\n",
    "                   \"The heartache, and the thousand natural shocks\",\n",
    "                   \"That flesh is heir to,--'tis a consummation\",\n",
    "                   \"Devoutly to be wish'd. To die,--to sleep;--\",\n",
    "                   \"To sleep! perchance to dream:--ay, there's the rub;\",\n",
    "                   \"For in that sleep of death what dreams may come,\",\n",
    "                   \"When we have shuffled off this mortal coil,\",\n",
    "                   \"Must give us pause: there's the respect\",\n",
    "                   \"That makes calamity of so long life;\",\n",
    "                   \"For who would bear the whips and scorns of time,\",\n",
    "                   \"The oppressor's wrong, the proud man's contumely,\",\n",
    "                   \"The pangs of despis'd love, the law's delay,\",\n",
    "                   \"The insolence of office, and the spurns\",\n",
    "                   \"That patient merit of the unworthy takes,\",\n",
    "                   \"When he himself might his quietus make\",\n",
    "                   \"With a bare bodkin? who would these fardels bear,\",\n",
    "                   \"To grunt and sweat under a weary life,\",\n",
    "                   \"But that the dread of something after death,--\",\n",
    "                   \"The undiscover'd country, from whose bourn\",\n",
    "                   \"No traveller returns,--puzzles the will,\",\n",
    "                   \"And makes us rather bear those ills we have\",\n",
    "                   \"Than fly to others that we know not of?\",\n",
    "                   \"Thus conscience does make cowards of us all;\",\n",
    "                   \"And thus the native hue of resolution\",\n",
    "                   \"Is sicklied o'er with the pale cast of thought;\",\n",
    "                   \"And enterprises of great pith and moment,\",\n",
    "                   \"With this regard, their currents turn awry,\",\n",
    "                   \"And lose the name of action.--Soft you now!\",\n",
    "                   \"The fair Ophelia!--Nymph, in thy orisons\",\n",
    "                   \"Be all my sins remember'd.\"]\n",
    "\n",
    "\n",
    "def word_count(input_path, output_path):\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.set_runtime_mode(RuntimeExecutionMode.BATCH)\n",
    "    # write all the data to one file\n",
    "    env.set_parallelism(1)\n",
    "\n",
    "    # define the source\n",
    "    if input_path is not None:\n",
    "        ds = env.from_source(\n",
    "            source=FileSource.for_record_stream_format(StreamFormat.text_line_format(),\n",
    "                                                       input_path)\n",
    "                             .process_static_file_set().build(),\n",
    "            watermark_strategy=WatermarkStrategy.for_monotonous_timestamps(),\n",
    "            source_name=\"file_source\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Executing word_count example with default input data set.\")\n",
    "        print(\"Use --input to specify file input.\")\n",
    "        ds = env.from_collection(word_count_data)\n",
    "\n",
    "    def split(line):\n",
    "        yield from line.split()\n",
    "\n",
    "    # compute word count\n",
    "    ds = ds.flat_map(split) \\\n",
    "        .map(lambda i: (i, 1), output_type=Types.TUPLE([Types.STRING(), Types.INT()])) \\\n",
    "        .key_by(lambda i: i[0]) \\\n",
    "        .reduce(lambda i, j: (i[0], i[1] + j[1]))\n",
    "\n",
    "    # define the sink\n",
    "    if output_path is not None:\n",
    "        ds.sink_to(\n",
    "            sink=FileSink.for_row_format(\n",
    "                base_path=output_path,\n",
    "                encoder=Encoder.simple_string_encoder())\n",
    "            .with_output_file_config(\n",
    "                OutputFileConfig.builder()\n",
    "                .with_part_prefix(\"prefix\")\n",
    "                .with_part_suffix(\".ext\")\n",
    "                .build())\n",
    "            .with_rolling_policy(RollingPolicy.default_rolling_policy())\n",
    "            .build()\n",
    "        )\n",
    "    else:\n",
    "        print(\"Printing result to stdout. Use --output to specify output path.\")\n",
    "        ds.print()\n",
    "\n",
    "    # submit for execution\n",
    "    env.execute()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--input',\n",
    "        dest='input',\n",
    "        required=False,\n",
    "        help='Input file to process.')\n",
    "    parser.add_argument(\n",
    "        '--output',\n",
    "        dest='output',\n",
    "        required=False,\n",
    "        help='Output file to write results to.')\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    known_args, _ = parser.parse_known_args(argv)\n",
    "\n",
    "    word_count(known_args.input, known_args.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing word_count example with default input data set.\n",
      "Use --input to specify file input.\n",
      "Printing result to stdout. Use --output to specify output path.\n"
     ]
    }
   ],
   "source": [
    "# Test with a Flink Python Table API Program\n",
    "# The following code comes from the official [documents version 1.18](https://nightlies.apache.org/flink/flink-docs-release-1.18/zh/docs/dev/python/table_api_tutorial/).\n",
    "# Save the code below as `Table_API_word_count.py`.\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from pyflink.common import Row\n",
    "from pyflink.table import (EnvironmentSettings, TableEnvironment, TableDescriptor, Schema,\n",
    "                           DataTypes, FormatDescriptor)\n",
    "from pyflink.table.expressions import lit, col\n",
    "from pyflink.table.udf import udtf\n",
    "\n",
    "word_count_data = [\"To be, or not to be,--that is the question:--\",\n",
    "                   \"Whether 'tis nobler in the mind to suffer\",\n",
    "                   \"The slings and arrows of outrageous fortune\",\n",
    "                   \"Or to take arms against a sea of troubles,\",\n",
    "                   \"And by opposing end them?--To die,--to sleep,--\",\n",
    "                   \"No more; and by a sleep to say we end\",\n",
    "                   \"The heartache, and the thousand natural shocks\",\n",
    "                   \"That flesh is heir to,--'tis a consummation\",\n",
    "                   \"Devoutly to be wish'd. To die,--to sleep;--\",\n",
    "                   \"To sleep! perchance to dream:--ay, there's the rub;\",\n",
    "                   \"For in that sleep of death what dreams may come,\",\n",
    "                   \"When we have shuffled off this mortal coil,\",\n",
    "                   \"Must give us pause: there's the respect\",\n",
    "                   \"That makes calamity of so long life;\",\n",
    "                   \"For who would bear the whips and scorns of time,\",\n",
    "                   \"The oppressor's wrong, the proud man's contumely,\",\n",
    "                   \"The pangs of despis'd love, the law's delay,\",\n",
    "                   \"The insolence of office, and the spurns\",\n",
    "                   \"That patient merit of the unworthy takes,\",\n",
    "                   \"When he himself might his quietus make\",\n",
    "                   \"With a bare bodkin? who would these fardels bear,\",\n",
    "                   \"To grunt and sweat under a weary life,\",\n",
    "                   \"But that the dread of something after death,--\",\n",
    "                   \"The undiscover'd country, from whose bourn\",\n",
    "                   \"No traveller returns,--puzzles the will,\",\n",
    "                   \"And makes us rather bear those ills we have\",\n",
    "                   \"Than fly to others that we know not of?\",\n",
    "                   \"Thus conscience does make cowards of us all;\",\n",
    "                   \"And thus the native hue of resolution\",\n",
    "                   \"Is sicklied o'er with the pale cast of thought;\",\n",
    "                   \"And enterprises of great pith and moment,\",\n",
    "                   \"With this regard, their currents turn awry,\",\n",
    "                   \"And lose the name of action.--Soft you now!\",\n",
    "                   \"The fair Ophelia!--Nymph, in thy orisons\",\n",
    "                   \"Be all my sins remember'd.\"]\n",
    "\n",
    "\n",
    "def word_count(input_path, output_path):\n",
    "    t_env = TableEnvironment.create(EnvironmentSettings.in_streaming_mode())\n",
    "    # write all the data to one file\n",
    "    t_env.get_config().set(\"parallelism.default\", \"1\")\n",
    "\n",
    "    # define the source\n",
    "    if input_path is not None:\n",
    "        t_env.create_temporary_table(\n",
    "            'source',\n",
    "            TableDescriptor.for_connector('filesystem')\n",
    "                .schema(Schema.new_builder()\n",
    "                        .column('word', DataTypes.STRING())\n",
    "                        .build())\n",
    "                .option('path', input_path)\n",
    "                .format('csv')\n",
    "                .build())\n",
    "        tab = t_env.from_path('source')\n",
    "    else:\n",
    "        print(\"Executing word_count example with default input data set.\")\n",
    "        print(\"Use --input to specify file input.\")\n",
    "        tab = t_env.from_elements(map(lambda i: (i,), word_count_data),\n",
    "                                  DataTypes.ROW([DataTypes.FIELD('line', DataTypes.STRING())]))\n",
    "\n",
    "    # define the sink\n",
    "    if output_path is not None:\n",
    "        t_env.create_temporary_table(\n",
    "            'sink',\n",
    "            TableDescriptor.for_connector('filesystem')\n",
    "                .schema(Schema.new_builder()\n",
    "                        .column('word', DataTypes.STRING())\n",
    "                        .column('count', DataTypes.BIGINT())\n",
    "                        .build())\n",
    "                .option('path', output_path)\n",
    "                .format(FormatDescriptor.for_format('canal-json')\n",
    "                        .build())\n",
    "                .build())\n",
    "    else:\n",
    "        print(\"Printing result to stdout. Use --output to specify output path.\")\n",
    "        t_env.create_temporary_table(\n",
    "            'sink',\n",
    "            TableDescriptor.for_connector('print')\n",
    "                .schema(Schema.new_builder()\n",
    "                        .column('word', DataTypes.STRING())\n",
    "                        .column('count', DataTypes.BIGINT())\n",
    "                        .build())\n",
    "                .build())\n",
    "\n",
    "    @udtf(result_types=[DataTypes.STRING()])\n",
    "    def split(line: Row):\n",
    "        for s in line[0].split():\n",
    "            yield Row(s)\n",
    "\n",
    "    # compute word count\n",
    "    tab.flat_map(split).alias('word') \\\n",
    "        .group_by(col('word')) \\\n",
    "        .select(col('word'), lit(1).count) \\\n",
    "        .execute_insert('sink') \\\n",
    "        .wait()\n",
    "    # remove .wait if submitting to a remote cluster, refer to\n",
    "    # https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/python/faq/#wait-for-jobs-to-finish-when-executing-jobs-in-mini-cluster\n",
    "    # for more details\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--input',\n",
    "        dest='input',\n",
    "        required=False,\n",
    "        help='Input file to process.')\n",
    "    parser.add_argument(\n",
    "        '--output',\n",
    "        dest='output',\n",
    "        required=False,\n",
    "        help='Output file to write results to.')\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    known_args, _ = parser.parse_known_args(argv)\n",
    "\n",
    "    word_count(known_args.input, known_args.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
